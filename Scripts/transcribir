{"cells":[{"cell_type":"markdown","metadata":{"id":"v5hvo8QWN-a9"},"source":["Whisper - Notebook creado por [DotCSV](https://www.youtube.com/channel/UCy5znSnfMsDwaLlROnZ7Qbg)"]},{"cell_type":"markdown","metadata":{"id":"f-BcD0b8hwdA"},"source":["Ten activada la **Aceleración por hardware** con GPU en `\"Entorno de ejecución\" > \"Cambiar tipo de entorno de ejecución\"`"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113429,"status":"ok","timestamp":1718136500797,"user":{"displayName":"Gerardo Dávila Hernández","userId":"07224802693534110105"},"user_tz":360},"id":"t5BkYPBVbI2Q","outputId":"ea79844c-205b-4ef9-abd4-b2163a10944f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ev5skpai\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ev5skpai\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n","Collecting tiktoken (from openai-whisper==20231117)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=56ff08d52eff16f696fdf789d1d6a941384f3b3beac1863701905249546c1351\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dqvbm072/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n","Successfully built openai-whisper\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n","Collecting jiwer\n","  Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n","Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n","Collecting rapidfuzz<4,>=3 (from jiwer)\n","  Downloading rapidfuzz-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n","Successfully installed jiwer-3.0.4 rapidfuzz-3.9.3\n","Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: ffmpeg\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=af7bb422121419ed0184bfa4e44125845b68a34e3fa41fda22c59b75327d902b\n","  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n","Successfully built ffmpeg\n","Installing collected packages: ffmpeg\n","Successfully installed ffmpeg-1.4\n"]}],"source":["!pip install git+https://github.com/openai/whisper.git\n","!pip install jiwer\n","!pip install ffmpeg"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","executionInfo":{"elapsed":384,"status":"ok","timestamp":1718136501164,"user":{"displayName":"Gerardo Dávila Hernández","userId":"07224802693534110105"},"user_tz":360},"id":"SJl7HJOeo0-P"},"outputs":[],"source":["#@title Ejecutar esta celda para instalar las librería.\n","\"\"\"\n","To write this piece of code I took inspiration/code from a lot of places.\n","It was late night, so I'm not sure how much I created or just copied o.O\n","Here are some of the possible references:\n","https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n","https://stackoverflow.com/a/18650249\n","https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n","https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n","https://stackoverflow.com/a/49019356\n","\"\"\"\n","\n","\n","\n","from IPython.display import HTML, Audio\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import numpy as np\n","from scipy.io.wavfile import read as wav_read\n","import io\n","import ffmpeg\n","\n","AUDIO_HTML = \"\"\"\n","<script>\n","var my_div = document.createElement(\"DIV\");\n","var my_p = document.createElement(\"P\");\n","var my_btn = document.createElement(\"BUTTON\");\n","var t = document.createTextNode(\"Press to start recording\");\n","\n","my_btn.appendChild(t);\n","//my_p.appendChild(my_btn);\n","my_div.appendChild(my_btn);\n","document.body.appendChild(my_div);\n","\n","var base64data = 0;\n","var reader;\n","var recorder, gumStream;\n","var recordButton = my_btn;\n","\n","var handleSuccess = function(stream) {\n","  gumStream = stream;\n","  var options = {\n","    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n","    mimeType : 'audio/webm;codecs=opus'\n","    //mimeType : 'audio/webm;codecs=pcm'\n","  };\n","  //recorder = new MediaRecorder(stream, options);\n","  recorder = new MediaRecorder(stream);\n","  recorder.ondataavailable = function(e) {\n","    var url = URL.createObjectURL(e.data);\n","    var preview = document.createElement('audio');\n","    preview.controls = true;\n","    preview.src = url;\n","    document.body.appendChild(preview);\n","\n","    reader = new FileReader();\n","    reader.readAsDataURL(e.data);\n","    reader.onloadend = function() {\n","      base64data = reader.result;\n","      //console.log(\"Inside FileReader:\" + base64data);\n","    }\n","  };\n","  recorder.start();\n","  };\n","\n","recordButton.innerText = \"Recording... press to stop\";\n","\n","navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n","\n","\n","function toggleRecording() {\n","  if (recorder && recorder.state == \"recording\") {\n","      recorder.stop();\n","      gumStream.getAudioTracks()[0].stop();\n","      recordButton.innerText = \"Saving the recording... pls wait!\"\n","  }\n","}\n","\n","// https://stackoverflow.com/a/951057\n","function sleep(ms) {\n","  return new Promise(resolve => setTimeout(resolve, ms));\n","}\n","\n","var data = new Promise(resolve=>{\n","//recordButton.addEventListener(\"click\", toggleRecording);\n","recordButton.onclick = ()=>{\n","toggleRecording()\n","\n","sleep(2000).then(() => {\n","  // wait 2000ms for the data to be available...\n","  // ideally this should use something like await...\n","  //console.log(\"Inside data:\" + base64data)\n","  resolve(base64data.toString())\n","\n","});\n","\n","}\n","});\n","\n","</script>\n","\"\"\"\n","\n","def get_audio():\n","  display(HTML(AUDIO_HTML))\n","  data = eval_js(\"data\")\n","  binary = b64decode(data.split(',')[1])\n","\n","  process = (ffmpeg\n","    .input('pipe:0')\n","    .output('pipe:1', format='wav')\n","    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n","  )\n","  output, err = process.communicate(input=binary)\n","\n","  riff_chunk_size = len(output) - 8\n","  # Break up the chunk size into four bytes, held in b.\n","  q = riff_chunk_size\n","  b = []\n","  for i in range(4):\n","      q, r = divmod(q, 256)\n","      b.append(r)\n","\n","  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n","  riff = output[:4] + bytes(b) + output[8:]\n","\n","  sr, audio = wav_read(io.BytesIO(riff))\n","\n","  return audio, sr"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27090,"status":"ok","timestamp":1718136543470,"user":{"displayName":"Gerardo Dávila Hernández","userId":"07224802693534110105"},"user_tz":360},"id":"SQa8ttMnCZRo","outputId":"f2330a00-81e9-4ddf-a9db-7b3b626945c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4159,"status":"ok","timestamp":1706925586728,"user":{"displayName":"Gerardo Dávila Hernández","userId":"07224802693534110105"},"user_tz":360},"id":"qLc6HyTOsGIi","outputId":"56b5e54a-a853-49a4-decd-5550e2f6d898"},"outputs":[{"name":"stdout","output_type":"stream","text":["usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n","               [--output_dir OUTPUT_DIR] [--output_format {txt,vtt,srt,tsv,json,all}]\n","               [--verbose VERBOSE] [--task {transcribe,translate}]\n","               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n","               [--temperature TEMPERATURE] [--best_of BEST_OF] [--beam_size BEAM_SIZE]\n","               [--patience PATIENCE] [--length_penalty LENGTH_PENALTY]\n","               [--suppress_tokens SUPPRESS_TOKENS] [--initial_prompt INITIAL_PROMPT]\n","               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT] [--fp16 FP16]\n","               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n","               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n","               [--logprob_threshold LOGPROB_THRESHOLD] [--no_speech_threshold NO_SPEECH_THRESHOLD]\n","               [--word_timestamps WORD_TIMESTAMPS] [--prepend_punctuations PREPEND_PUNCTUATIONS]\n","               [--append_punctuations APPEND_PUNCTUATIONS] [--highlight_words HIGHLIGHT_WORDS]\n","               [--max_line_width MAX_LINE_WIDTH] [--max_line_count MAX_LINE_COUNT]\n","               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n","               [--clip_timestamps CLIP_TIMESTAMPS]\n","               [--hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD]\n","               audio [audio ...]\n","\n","positional arguments:\n","  audio                 audio file(s) to transcribe\n","\n","options:\n","  -h, --help            show this help message and exit\n","  --model MODEL         name of the Whisper model to use (default: small)\n","  --model_dir MODEL_DIR\n","                        the path to save model files; uses ~/.cache/whisper by default (default:\n","                        None)\n","  --device DEVICE       device to use for PyTorch inference (default: cuda)\n","  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n","                        directory to save the outputs (default: .)\n","  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n","                        format of the output file; if not specified, all available formats will be\n","                        produced (default: all)\n","  --verbose VERBOSE     whether to print out the progress and debug messages (default: True)\n","  --task {transcribe,translate}\n","                        whether to perform X->X speech recognition ('transcribe') or X->English\n","                        translation ('translate') (default: transcribe)\n","  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n","                        language spoken in the audio, specify None to perform language detection\n","                        (default: None)\n","  --temperature TEMPERATURE\n","                        temperature to use for sampling (default: 0)\n","  --best_of BEST_OF     number of candidates when sampling with non-zero temperature (default: 5)\n","  --beam_size BEAM_SIZE\n","                        number of beams in beam search, only applicable when temperature is zero\n","                        (default: 5)\n","  --patience PATIENCE   optional patience value to use in beam decoding, as in\n","                        https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to\n","                        conventional beam search (default: None)\n","  --length_penalty LENGTH_PENALTY\n","                        optional token length penalty coefficient (alpha) as in\n","                        https://arxiv.org/abs/1609.08144, uses simple length normalization by\n","                        default (default: None)\n","  --suppress_tokens SUPPRESS_TOKENS\n","                        comma-separated list of token ids to suppress during sampling; '-1' will\n","                        suppress most special characters except common punctuations (default: -1)\n","  --initial_prompt INITIAL_PROMPT\n","                        optional text to provide as a prompt for the first window. (default: None)\n","  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n","                        if True, provide the previous output of the model as a prompt for the next\n","                        window; disabling may make the text inconsistent across windows, but the\n","                        model becomes less prone to getting stuck in a failure loop (default:\n","                        True)\n","  --fp16 FP16           whether to perform inference in fp16; True by default (default: True)\n","  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n","                        temperature to increase when falling back when the decoding fails to meet\n","                        either of the thresholds below (default: 0.2)\n","  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n","                        if the gzip compression ratio is higher than this value, treat the\n","                        decoding as failed (default: 2.4)\n","  --logprob_threshold LOGPROB_THRESHOLD\n","                        if the average log probability is lower than this value, treat the\n","                        decoding as failed (default: -1.0)\n","  --no_speech_threshold NO_SPEECH_THRESHOLD\n","                        if the probability of the <|nospeech|> token is higher than this value AND\n","                        the decoding has failed due to `logprob_threshold`, consider the segment\n","                        as silence (default: 0.6)\n","  --word_timestamps WORD_TIMESTAMPS\n","                        (experimental) extract word-level timestamps and refine the results based\n","                        on them (default: False)\n","  --prepend_punctuations PREPEND_PUNCTUATIONS\n","                        if word_timestamps is True, merge these punctuation symbols with the next\n","                        word (default: \"'“¿([{-)\n","  --append_punctuations APPEND_PUNCTUATIONS\n","                        if word_timestamps is True, merge these punctuation symbols with the\n","                        previous word (default: \"'.。,，!！?？:：”)]}、)\n","  --highlight_words HIGHLIGHT_WORDS\n","                        (requires --word_timestamps True) underline each word as it is spoken in\n","                        srt and vtt (default: False)\n","  --max_line_width MAX_LINE_WIDTH\n","                        (requires --word_timestamps True) the maximum number of characters in a\n","                        line before breaking the line (default: None)\n","  --max_line_count MAX_LINE_COUNT\n","                        (requires --word_timestamps True) the maximum number of lines in a segment\n","                        (default: None)\n","  --max_words_per_line MAX_WORDS_PER_LINE\n","                        (requires --word_timestamps True, no effect with --max_line_width) the\n","                        maximum number of words in a segment (default: None)\n","  --threads THREADS     number of threads used by torch for CPU inference; supercedes\n","                        MKL_NUM_THREADS/OMP_NUM_THREADS (default: 0)\n","  --clip_timestamps CLIP_TIMESTAMPS\n","                        comma-separated list start,end,start,end,... timestamps (in seconds) of\n","                        clips to process, where the last end timestamp defaults to the end of the\n","                        file (default: 0)\n","  --hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD\n","                        (requires --word_timestamps True) skip silent periods longer than this\n","                        threshold (in seconds) when a possible hallucination is detected (default:\n","                        None)\n"]}],"source":["!whisper --help"]},{"cell_type":"markdown","metadata":{"id":"XXZooJ-Wy9EL"},"source":["Transcribir"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aejy9Haxy81U","executionInfo":{"status":"ok","timestamp":1718140565869,"user_tz":360,"elapsed":3965560,"user":{"displayName":"Gerardo Dávila Hernández","userId":"07224802693534110105"}},"outputId":"4b73bda0-edfb-43c5-dbe5-5570b6e81225"},"outputs":[{"output_type":"stream","name":"stdout","text":["100%|█████████████████████████████████████| 2.88G/2.88G [00:39<00:00, 77.6MiB/s]\n","Detected language: Spanish\n","100% 644054/644054 [1:04:14<00:00, 167.08frames/s]\n"]}],"source":["!whisper '/content/drive/MyDrive/percepciones/Audios/9_ramon.m4a' --task transcribe --model large --verbose False --output_format txt --output_dir \"/content/drive/MyDrive/percepciones/Audios/Transcricpiones\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1McHflyiDVZ7ihBRClWKDf8njoUKOVRzN","timestamp":1708542507041},{"file_id":"1CvvYPAFemIZdSOt9fhN541esSlZR7Ic6","timestamp":1677555290542},{"file_id":"1lXtPVNqMy-lg1QrGOG9qZ96rOXNMnNrh","timestamp":1668360149938},{"file_id":"https://github.com/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb","timestamp":1667820298272}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}